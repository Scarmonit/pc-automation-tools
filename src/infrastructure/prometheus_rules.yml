# Prometheus Alerting Rules for AI Swarm Intelligence System
groups:
  - name: swarm_health_alerts
    interval: 30s
    rules:
      # Service Health Alerts
      - alert: ServiceDown
        expr: up == 0
        for: 1m
        labels:
          severity: critical
          service: "{{ $labels.job }}"
        annotations:
          summary: "Service {{ $labels.job }} is down"
          description: "{{ $labels.job }} service has been down for more than 1 minute."
          runbook_url: "https://docs.yourcompany.com/runbooks/service-down"

      - alert: ServiceDegraded
        expr: up == 0
        for: 30s
        labels:
          severity: warning
          service: "{{ $labels.job }}"
        annotations:
          summary: "Service {{ $labels.job }} is degraded"
          description: "{{ $labels.job }} service is experiencing issues."

  - name: swarm_performance_alerts
    interval: 30s
    rules:
      # Response Time Alerts
      - alert: HighResponseTime
        expr: http_request_duration_seconds{quantile="0.95"} > 5
        for: 2m
        labels:
          severity: warning
          service: "{{ $labels.job }}"
        annotations:
          summary: "High response time on {{ $labels.job }}"
          description: "95th percentile response time is {{ $value }}s for {{ $labels.job }}"

      - alert: CriticalResponseTime
        expr: http_request_duration_seconds{quantile="0.95"} > 10
        for: 1m
        labels:
          severity: critical
          service: "{{ $labels.job }}"
        annotations:
          summary: "Critical response time on {{ $labels.job }}"
          description: "95th percentile response time is {{ $value }}s for {{ $labels.job }}"

      # Error Rate Alerts
      - alert: HighErrorRate
        expr: |
          (
            rate(http_requests_total{status=~"5.."}[5m]) /
            rate(http_requests_total[5m])
          ) * 100 > 5
        for: 2m
        labels:
          severity: warning
          service: "{{ $labels.job }}"
        annotations:
          summary: "High error rate on {{ $labels.job }}"
          description: "Error rate is {{ $value }}% for {{ $labels.job }}"

      - alert: CriticalErrorRate
        expr: |
          (
            rate(http_requests_total{status=~"5.."}[5m]) /
            rate(http_requests_total[5m])
          ) * 100 > 15
        for: 1m
        labels:
          severity: critical
          service: "{{ $labels.job }}"
        annotations:
          summary: "Critical error rate on {{ $labels.job }}"
          description: "Error rate is {{ $value }}% for {{ $labels.job }}"

  - name: swarm_resource_alerts
    interval: 30s
    rules:
      # Memory Usage Alerts
      - alert: HighMemoryUsage
        expr: |
          (
            process_resident_memory_bytes / 
            (node_memory_MemTotal_bytes - node_memory_MemFree_bytes - node_memory_Buffers_bytes - node_memory_Cached_bytes)
          ) * 100 > 80
        for: 2m
        labels:
          severity: warning
          service: "{{ $labels.job }}"
        annotations:
          summary: "High memory usage on {{ $labels.job }}"
          description: "Memory usage is {{ $value }}% for {{ $labels.job }}"

      - alert: CriticalMemoryUsage
        expr: |
          (
            process_resident_memory_bytes / 
            (node_memory_MemTotal_bytes - node_memory_MemFree_bytes - node_memory_Buffers_bytes - node_memory_Cached_bytes)
          ) * 100 > 95
        for: 1m
        labels:
          severity: critical
          service: "{{ $labels.job }}"
        annotations:
          summary: "Critical memory usage on {{ $labels.job }}"
          description: "Memory usage is {{ $value }}% for {{ $labels.job }}"

      # CPU Usage Alerts
      - alert: HighCPUUsage
        expr: |
          (
            rate(process_cpu_seconds_total[5m]) * 100
          ) > 80
        for: 2m
        labels:
          severity: warning
          service: "{{ $labels.job }}"
        annotations:
          summary: "High CPU usage on {{ $labels.job }}"
          description: "CPU usage is {{ $value }}% for {{ $labels.job }}"

      - alert: CriticalCPUUsage
        expr: |
          (
            rate(process_cpu_seconds_total[5m]) * 100
          ) > 95
        for: 1m
        labels:
          severity: critical
          service: "{{ $labels.job }}"
        annotations:
          summary: "Critical CPU usage on {{ $labels.job }}"
          description: "CPU usage is {{ $value }}% for {{ $labels.job }}"

  - name: swarm_autogpt_alerts
    interval: 30s
    rules:
      # AutoGPT Specific Alerts
      - alert: AutoGPTTaskFailureRate
        expr: |
          (
            rate(autogpt_tasks_failed_total[10m]) /
            rate(autogpt_tasks_total[10m])
          ) * 100 > 10
        for: 2m
        labels:
          severity: warning
          service: "autogpt"
        annotations:
          summary: "High AutoGPT task failure rate"
          description: "AutoGPT task failure rate is {{ $value }}%"

      - alert: AutoGPTCircuitBreakerOpen
        expr: circuit_breaker_state{state="open"} == 1
        for: 0m
        labels:
          severity: error
          service: "{{ $labels.service }}"
        annotations:
          summary: "Circuit breaker open for {{ $labels.service }}"
          description: "Circuit breaker is open for {{ $labels.service }}, indicating service issues"

      - alert: AutoGPTQueueDepth
        expr: autogpt_queue_depth > 100
        for: 5m
        labels:
          severity: warning
          service: "autogpt"
        annotations:
          summary: "AutoGPT queue depth is high"
          description: "AutoGPT queue has {{ $value }} pending tasks"

      - alert: AutoGPTCriticalQueueDepth
        expr: autogpt_queue_depth > 500
        for: 1m
        labels:
          severity: critical
          service: "autogpt"
        annotations:
          summary: "AutoGPT queue depth is critically high"
          description: "AutoGPT queue has {{ $value }} pending tasks"

  - name: swarm_database_alerts
    interval: 30s
    rules:
      # Database Sync Alerts
      - alert: DatabaseSyncLag
        expr: database_sync_lag_seconds > 300
        for: 2m
        labels:
          severity: warning
          service: "database-sync"
        annotations:
          summary: "Database synchronization lag is high"
          description: "Database sync lag is {{ $value }} seconds"

      - alert: DatabaseSyncConflicts
        expr: increase(database_sync_conflicts_total[10m]) > 5
        for: 1m
        labels:
          severity: error
          service: "database-sync"
        annotations:
          summary: "High number of database sync conflicts"
          description: "{{ $value }} sync conflicts in the last 10 minutes"

      - alert: DatabaseConnectionFailure
        expr: database_connection_failures_total > 0
        for: 0m
        labels:
          severity: critical
          service: "database"
        annotations:
          summary: "Database connection failure"
          description: "Database connection failures detected"

  - name: swarm_api_bridge_alerts
    interval: 30s
    rules:
      # API Bridge Alerts
      - alert: ApiBridgeFailoverActivated
        expr: api_bridge_failovers_total > 0
        for: 0m
        labels:
          severity: warning
          service: "api-bridge"
        annotations:
          summary: "API Bridge failover activated"
          description: "API Bridge has activated failover mechanisms"

      - alert: ApiBridgeEndpointsUnhealthy
        expr: |
          (
            api_bridge_healthy_endpoints /
            api_bridge_total_endpoints
          ) * 100 < 50
        for: 1m
        labels:
          severity: critical
          service: "api-bridge"
        annotations:
          summary: "Majority of API Bridge endpoints are unhealthy"
          description: "Only {{ $value }}% of API Bridge endpoints are healthy"

      - alert: ApiBridgeRateLimitExceeded
        expr: increase(api_bridge_rate_limit_exceeded_total[5m]) > 50
        for: 1m
        labels:
          severity: warning
          service: "api-bridge"
        annotations:
          summary: "API Bridge rate limit frequently exceeded"
          description: "Rate limit exceeded {{ $value }} times in 5 minutes"

  - name: swarm_system_alerts
    interval: 30s
    rules:
      # System Resource Alerts
      - alert: HostHighDiskUsage
        expr: |
          (
            (node_filesystem_size_bytes - node_filesystem_free_bytes) /
            node_filesystem_size_bytes
          ) * 100 > 85
        for: 2m
        labels:
          severity: warning
          device: "{{ $labels.device }}"
        annotations:
          summary: "High disk usage on {{ $labels.device }}"
          description: "Disk usage is {{ $value }}% on {{ $labels.device }}"

      - alert: HostCriticalDiskUsage
        expr: |
          (
            (node_filesystem_size_bytes - node_filesystem_free_bytes) /
            node_filesystem_size_bytes
          ) * 100 > 95
        for: 1m
        labels:
          severity: critical
          device: "{{ $labels.device }}"
        annotations:
          summary: "Critical disk usage on {{ $labels.device }}"
          description: "Disk usage is {{ $value }}% on {{ $labels.device }}"

      - alert: HostHighMemoryUsage
        expr: |
          (
            (node_memory_MemTotal_bytes - node_memory_MemFree_bytes - node_memory_Buffers_bytes - node_memory_Cached_bytes) /
            node_memory_MemTotal_bytes
          ) * 100 > 90
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "High memory usage on host"
          description: "Host memory usage is {{ $value }}%"

      - alert: HostHighCPUUsage
        expr: 100 - (avg(irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 90
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "High CPU usage on host"
          description: "Host CPU usage is {{ $value }}%"

  - name: swarm_docker_alerts
    interval: 30s
    rules:
      # Docker Container Alerts
      - alert: ContainerRestarted
        expr: increase(container_last_restart_count[5m]) > 0
        for: 0m
        labels:
          severity: warning
          container: "{{ $labels.name }}"
        annotations:
          summary: "Container {{ $labels.name }} restarted"
          description: "Container {{ $labels.name }} has restarted"

      - alert: ContainerHighMemoryUsage
        expr: |
          (
            container_memory_usage_bytes /
            container_spec_memory_limit_bytes
          ) * 100 > 90
        for: 2m
        labels:
          severity: warning
          container: "{{ $labels.name }}"
        annotations:
          summary: "Container {{ $labels.name }} high memory usage"
          description: "Container memory usage is {{ $value }}%"

      - alert: ContainerHighCPUUsage
        expr: |
          (
            rate(container_cpu_usage_seconds_total[5m]) * 100
          ) > 90
        for: 2m
        labels:
          severity: warning
          container: "{{ $labels.name }}"
        annotations:
          summary: "Container {{ $labels.name }} high CPU usage"
          description: "Container CPU usage is {{ $value }}%"

  - name: swarm_integration_alerts
    interval: 30s
    rules:
      # Integration Health Alerts
      - alert: IntegrationValidationFailure
        expr: integration_validation_failures_total > 0
        for: 0m
        labels:
          severity: error
          service: "integration-validator"
        annotations:
          summary: "Integration validation failure detected"
          description: "Integration validation has detected {{ $value }} failures"

      - alert: ServiceDependencyFailure
        expr: service_dependency_check_failures > 0
        for: 1m
        labels:
          severity: critical
          service: "{{ $labels.service }}"
        annotations:
          summary: "Service dependency failure for {{ $labels.service }}"
          description: "Service {{ $labels.service }} has dependency failures"

      - alert: APIKeyExpiration
        expr: api_key_days_until_expiry < 30
        for: 0m
        labels:
          severity: warning
          api: "{{ $labels.api_name }}"
        annotations:
          summary: "API key {{ $labels.api_name }} expires soon"
          description: "API key for {{ $labels.api_name }} expires in {{ $value }} days"

      - alert: APIKeyExpired
        expr: api_key_days_until_expiry < 0
        for: 0m
        labels:
          severity: critical
          api: "{{ $labels.api_name }}"
        annotations:
          summary: "API key {{ $labels.api_name }} has expired"
          description: "API key for {{ $labels.api_name }} has expired"