# LLMStack Environment Configuration
# Copy this file to .env and update with your actual values

# Security Keys (CHANGE THESE!)
LLMSTACK_SECRET_KEY=5YhkO46-Etb_X5TLicGiJryX9Sd67C3-ICXxuxs2Y9n87FQcYt1wSCXCaUbvfSNJ8r8
JWT_SECRET_KEY=Eft0jK7x95IHP9-HyOyZjjMkX52Ss_VT57wU1E75NIvyqhCBiQaPKP2eqYgsKOuKKsU

# Database Configuration
DATABASE_URL=postgresql://postgres:${POSTGRES_PASSWORD}@localhost:5432/llmstack
POSTGRES_PASSWORD=4N@oSSfiwWWUxh&w

# Redis Configuration  
REDIS_URL=redis://localhost:6379/0
REDIS_PASSWORD=uWwegL8GG6PZQCe^

# Authentication (for auto_login.py)
LOGIN_EMAIL=your-email@example.com
LOGIN_PASSWORD=your-secure-password

# API Keys (set these if using external services)
OPENAI_API_KEY=your-openai-key-here
ANTHROPIC_API_KEY=your-anthropic-key-here

# Service URLs
OLLAMA_BASE_URL=http://localhost:11434
FLOWISE_URL=http://localhost:3001
OPENHANDS_URL=http://localhost:3002
GRAFANA_URL=http://localhost:3003

# Performance Settings
MAX_CONCURRENT_REQUESTS=10
REQUEST_TIMEOUT=30
WORKER_PROCESSES=4

# Feature Flags
ENABLE_AGENTS=true
ENABLE_RAG=true
ENABLE_WORKFLOWS=true
ENABLE_MONITORING=true

# Logging
LOG_LEVEL=INFO
LOG_FORMAT=json

# Security Settings
CORS_ORIGINS=http://localhost:3000,http://localhost:3001
ALLOWED_HOSTS=localhost,127.0.0.1
SECURE_COOKIES=true
