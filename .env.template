# LLMStack Environment Configuration
# Copy this file to .env and update with your actual values

# Security Keys (CHANGE THESE!)
LLMSTACK_SECRET_KEY=7jL9FG1Njln5lXhXSL7t_LxI1KtOUJGUzis42nl-dTB6KOfkuvRB1k6fTXKjmaC-iKc
JWT_SECRET_KEY=zVTejireHl4kLy8cH1eacaynsRW0K-mO0j8kUWDof78lC8tG7Nn2_6NH2uRfDFgJVFI

# Database Configuration
DATABASE_URL=postgresql://postgres:${POSTGRES_PASSWORD}@localhost:5432/llmstack
POSTGRES_PASSWORD=WWKtp@MUapbjgViM

# Redis Configuration  
REDIS_URL=redis://localhost:6379/0
REDIS_PASSWORD=h&1!#H*32eeX&5Zi

# Authentication (for auto_login.py)
LOGIN_EMAIL=your-email@example.com
LOGIN_PASSWORD=your-secure-password

# API Keys (set these if using external services)
OPENAI_API_KEY=your-openai-key-here
ANTHROPIC_API_KEY=your-anthropic-key-here

# Service URLs
OLLAMA_BASE_URL=http://localhost:11434
FLOWISE_URL=http://localhost:3001
OPENHANDS_URL=http://localhost:3002
GRAFANA_URL=http://localhost:3003

# Performance Settings
MAX_CONCURRENT_REQUESTS=10
REQUEST_TIMEOUT=30
WORKER_PROCESSES=4

# Feature Flags
ENABLE_AGENTS=true
ENABLE_RAG=true
ENABLE_WORKFLOWS=true
ENABLE_MONITORING=true

# Logging
LOG_LEVEL=INFO
LOG_FORMAT=json

# Security Settings
CORS_ORIGINS=http://localhost:3000,http://localhost:3001
ALLOWED_HOSTS=localhost,127.0.0.1
SECURE_COOKIES=true
