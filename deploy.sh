#!/bin/bash
# Master deployment script for LLMStack Open Source setup
# Based on compass1 artifact guide

set -e  # Exit on any error

echo "================================================================="
echo "  LLMSTACK OPEN SOURCE DEPLOYMENT"
echo "================================================================="
echo "Complete deployment with 100% free components"
echo "Zero API costs, full data privacy, production-ready system"
echo "================================================================="
echo

# Color codes for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

log_info() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

log_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

log_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

# Check if script is run from correct directory
if [ ! -f "scripts/check_system.sh" ]; then
    log_error "Please run this script from the repository root directory"
    exit 1
fi

# Make all scripts executable
chmod +x scripts/*.sh scripts/*.py

log_info "Starting LLMStack deployment..."

# Phase 0: System Requirements Check
echo
echo "==============================="
echo "PHASE 0: SYSTEM REQUIREMENTS"
echo "==============================="
log_info "Checking system requirements..."

if bash scripts/check_system.sh; then
    log_success "System requirements check passed"
else
    log_error "System requirements not met. Please address the issues above."
    exit 1
fi

# Phase 1: Install Local Model Servers
echo
echo "==============================="
echo "PHASE 1: LOCAL MODEL SERVERS"
echo "==============================="

log_info "Installing Ollama..."
if bash scripts/install_ollama.sh; then
    log_success "Ollama installed successfully"
else
    log_warning "Ollama installation had issues, continuing..."
fi

log_info "Installing LM Studio..."
if bash scripts/install_lm_studio.sh; then
    log_success "LM Studio installed successfully"
else
    log_warning "LM Studio installation had issues, continuing..."
fi

log_info "Setting up vLLM..."
if bash scripts/setup_vllm.sh; then
    log_success "vLLM setup completed"
else
    log_warning "vLLM setup had issues, continuing..."
fi

# Phase 2: Deploy LLMStack Base
echo
echo "==============================="
echo "PHASE 2: LLMSTACK DEPLOYMENT"
echo "==============================="

log_info "Deploying LLMStack..."
if bash scripts/deploy_llmstack.sh; then
    log_success "LLMStack deployed successfully"
else
    log_error "LLMStack deployment failed"
    exit 1
fi

# Phase 3: Install AI Agents
echo
echo "==============================="
echo "PHASE 3: AI AGENTS"
echo "==============================="

log_info "Installing AI agents..."
if bash scripts/install_agents.sh; then
    log_success "AI agents installed successfully"
else
    log_warning "Some AI agents had installation issues, continuing..."
fi

log_info "Installing Continue extension..."
if bash scripts/install_continue.sh; then
    log_success "Continue extension installed"
else
    log_warning "Continue extension installation skipped"
fi

log_info "Installing Jan desktop app..."
if bash scripts/install_jan.sh; then
    log_success "Jan installed successfully"
else
    log_warning "Jan installation had issues, continuing..."
fi

# Phase 4: Configuration
echo
echo "==============================="
echo "PHASE 4: CONFIGURATION"
echo "==============================="

log_info "Setting up monitoring..."
if bash scripts/setup_monitoring.sh; then
    log_success "Monitoring setup completed"
else
    log_warning "Monitoring setup had issues, continuing..."
fi

log_info "Optimizing system..."
if bash scripts/optimize_system.sh; then
    log_success "System optimization completed"
else
    log_warning "System optimization had issues, continuing..."
fi

# Phase 5: Validation
echo
echo "==============================="
echo "PHASE 5: VALIDATION"
echo "==============================="

log_info "Validating deployment..."
if bash scripts/validate_deployment.sh; then
    log_success "Deployment validation passed"
else
    log_warning "Deployment validation had issues, but core components may still work"
fi

# Phase 6: Performance Benchmark
echo
echo "==============================="
echo "PHASE 6: PERFORMANCE BENCHMARK"  
echo "==============================="

log_info "Running performance benchmark..."
if python3 scripts/benchmark_system.py; then
    log_success "Performance benchmark completed"
else
    log_warning "Performance benchmark had issues, continuing..."
fi

# Final Summary
echo
echo "================================================================="
echo "  DEPLOYMENT COMPLETE!"
echo "================================================================="
echo
log_success "LLMStack Open Source deployment finished!"
echo
echo "ðŸŽ¯ ACCESS POINTS:"
echo "  â€¢ LLMStack UI: http://localhost:3000"
echo "  â€¢ Flowise: http://localhost:3001" 
echo "  â€¢ OpenHands: http://localhost:3002"
echo "  â€¢ Grafana Monitoring: http://localhost:3003 (admin/admin)"
echo "  â€¢ Prometheus: http://localhost:9090"
echo
echo "ðŸ¤– AVAILABLE MODELS:"
echo "  â€¢ Ollama API: http://localhost:11434/v1"
echo "  â€¢ LM Studio: http://localhost:1234/v1"
echo "  â€¢ vLLM: http://localhost:8000/v1"
echo
echo "ðŸ’° COST BREAKDOWN:"
echo "  â€¢ Total API Cost: \$0.00"
echo "  â€¢ Data Privacy: 100% Local"
echo "  â€¢ Production Ready: YES"
echo
echo "ðŸ”§ NEXT STEPS:"
echo "  1. Open LLMStack UI and complete initial setup"
echo "  2. Configure providers with: python3 scripts/configure_providers.py <admin_token>"
echo "  3. Start building your AI applications!"
echo
echo "ðŸ“š For troubleshooting, see README.md"
echo "================================================================="