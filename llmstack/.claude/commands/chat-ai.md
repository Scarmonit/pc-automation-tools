Start an interactive chat session with a local AI model.

Ask the user which model they want to use, then start the appropriate Ollama model:
1. deepseek-r1:8b - For complex reasoning
2. llama3.1:8b - For general conversation  
3. dolphin-mistral:latest - For coding tasks
4. gemma2:27b - For large context tasks

Execute: `ollama run <chosen-model>`